% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/IRmapping_functions.R
\name{dynamic_resample}
\alias{dynamic_resample}
\title{Dynamic resampling}
\usage{
dynamic_resample(
  in_task,
  in_learner,
  in_resampling,
  type,
  store_models = FALSE
)
}
\arguments{
\item{in_task}{\link[mlr3]{Task} to resample}

\item{in_learner}{\link[mlr3]{Learner} to use in resampling (e.g., conditionel inference forest with minority class oversampling).
Can be a simple learner or an \link[mlr3tuning]{Autotuner} already including hyperparameter tuning strategy.}

\item{in_resampling}{\link[mlr3]{Resampling} cross-validation strategy}

\item{type}{(character) Type of learner 'classif' or 'regr'. Other values are not accepted.}

\item{store_models}{whether to keep the fitted model after the test set has been predicted. Set to TRUE if you want to further analyse the models or want to extract information like variable importance.}
}
\value{
\link[mlr3]{ResampleResult}
}
\description{
Runs a train-predict-test routine a.k.a. a resampling (possibly in parallel):
Repeatedly apply learner on a training set of task to train a model,
then use the trained model to predict observations
of a test set. Training and test sets are defined by the resampling.
}
\details{
The dynamic aspect of this model is that it runs 'reset_tuning' on the fly
to make sure that the hyperparameter search space matches the task (e.g., if the number of candidate
predictor variables has been reduced, it adjusts mtry)
}
